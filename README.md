# ğŸ§  Universal AI Agent â€” Productoo P4 Assistant  
*Conversational copilot for product managers, analysts & engineers building the P4 manufacturing suite.*  
_Last update: 2025-07-02_

---

## âœ¨ Key Features

| Category | Status | Details |
|----------|--------|---------|
| Conversational interface | **âœ…** | CLI (`main.py`) & Gradio UI (`ui.py`). |
| Knowledge retrieval (RAG) | **âœ…** | Chroma vector-store auto-enriched with every Q/A turn. |
| Web / semantic search | **âœ… / Î²** | DuckDuckGo & Wikipedia; Tavily search (optional). |
| Jira integration | **âœ…** | `jira_ideas_retriever` (list Ideas); **planned** `jira_issue_detail`, create/update. |
| File output | **âœ…** | `save_text_to_file` â†’ `./output/YYYY-MM-DD_HHMM.txt`. |
| Confluence ingestion | **âœ… (manual)** | `rag_confluence_loader.py` for bulk import. |

---

## ğŸ§© 3-Tier Memory & Learning Architecture

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€ Tier 0 â”€â”€â”€â”€â”€â”€â”€â”€â”  User Prefs Store (language = cz-en, formality = 0.4 â€¦)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  Tier 1 â€” Episodic Memory  
â”‚ ConversationSummary    â”‚  â€¢ Rolling summary ~50 exchanges  
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  Tier 2 â€” Long-Term Semantic Memory (Chroma)  
â”‚ Full chats, Jira, docs â”‚  â€¢ Recency-boosted, similarity > 0.78  
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

1. **Retriever** â†’ Tier 2 (recency-weighted)  
2. **Prompt builder** â†’ Tier 1 summary + Tier 0 prefs  
3. **LLM call** (GPT-4o by default)  
4. **Reflection agent** (Llama 3 8B) checks coherence/citations; rerolls if nutnÃ©  
5. Exchange persists back to Tier 2; summary updates Tier 1

_Why it matters:_ agent remembers your decisions & tone, keeps context window small, a reflection pass sniÅ¾uje halucinace.

---

## ğŸ—ï¸ Architecture Overview

```mermaid
flowchart TD
    subgraph UI
        A[CLI] -->|query| C(Agent)
        B[Gradio] --> C
    end
    C -->|tool calls| D[Tool Router]
    D --> E[Jira API]
    D --> F[Web / Tavily]
    D --> G[RAG Vector DB]
    C --> H[Reflection Agent]
    H -.-> C
```

---

## ğŸš€ Quick Start

```bash
# 1 ) Dependencies
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt

# 2 ) Secrets
cp .env.example .env  # fill in OPENAI_API_KEY, JIRA_AUTH_TOKEN, â€¦

# 3 ) Run
python main.py            # CLI
# or
python ui.py              # Web UI http://127.0.0.1:7860
```

### Required ENV

```dotenv
OPENAI_API_KEY="sk-â€¦"
JIRA_AUTH_TOKEN="atlassian-â€¦"
TAVILY_API_KEY=""        # optional
```

---

## ğŸ“‚ Project Layout

```
universalagent/
â”œâ”€â”€ main.py                 # conversational loop
â”œâ”€â”€ ui.py                   # Gradio front-end
â”œâ”€â”€ tools.py                # LangChain Tools
â”œâ”€â”€ core_memory.py          # 3-tier memory impl.  â† NEW
â”œâ”€â”€ reflection_agent.py     # self-critique layer  â† NEW
â”œâ”€â”€ jira_retriever.py       # low-level Jira REST
â”œâ”€â”€ rag_*                   # RAG loaders & helpers
â”œâ”€â”€ output/                 # exported answers
â””â”€â”€ rag_chroma_db/          # vector DB (ignored)
```

---

## ğŸ›£ï¸ Roadmap 2025 H2

| Quadrant | Epic | KPI / Definition of Done |
|----------|------|--------------------------|
| **Reliability & Memory** | **Feedback-safe short-term memory** | Latency â‰¤ 2 s @ 2 k messages |
| | Reflection agent v1 | 20 % drop in hallucination score |
| **Tools & Integrations** | `jira_issue_detail` + create/update | Epic â†” Stories auto-flow round-trip |
| | Confluence incremental sync | Nightly run, removed pages flagged `archived` |
| **Code Quality & CI** | Ruff + mypy gate | Coverage â‰¥ 80 % critical modules |
| | Docker + GH Actions | Push to GHCR on every tag |
| **LLM Backend** | Adapter layer (OpenAI / Anthropic / Ollama) | Swap model w/o touching business logic |
| | Fine-tune Llama 3 8B on PM transcripts | 5 % â†‘ helpfulness in eval harness |

---

## ğŸ¯ Immediate Priorities (next 2 weeks)

1. **Replace `ConversationBufferMemory` â†’ `ConversationSummaryBufferMemory`**  
2. **Implement retriever wrapper** with recency decay  
3. **Add `user_prefs.json`** and inject into every prompt  
4. **Integrate reflection agent** (ReAct + Self-Critique)  
5. **CI smoke test** with 20 real PM queries & LLM-as-judge scoring

---

## ğŸ§ª Evaluation Harness (CI)

* **Dataset:** `./eval/pm_queries.jsonl` (prompt, expected key-phrases)  
* **Metrics:** helpfulness, correctness, style, answer_tokens/context_tokens  
* **Gate:** PR blocked if score < 0.70

---

## ğŸ¤– Switching Models

| Model | Reasoning | Latency (EU) | Cost / 1k tok | Context |
|-------|-----------|--------------|---------------|---------|
| GPT-4o | â˜…â˜…â˜…â˜…â˜… | 1.0Ã— | \$0.005 | 128 k |
| Claude 3 Opus | â˜…â˜…â˜…â˜…â˜† | 1.3Ã— | \$0.009 | 200 k |
| Llama 3 70B (LoRA) | â˜…â˜…â˜… | 0.5Ã—* | \$0.0007 | 8 k |

\* assuming local GPU inference

_Default:_ GPT-4o for main reasoning, Llama 3 8B for reflection & embeddings.

---

## ğŸ™Œ Contributing / Ideas

Issues & PRs welcome â€“ or ping **@tomas.ventruba** on Slack. Please run the eval harness before opening a PR.

---

Â© Productoo s.r.o. 2025 â€“ internal use only.
