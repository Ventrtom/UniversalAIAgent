"""tools.py â€” Unified LangChain Tools for the P4 Assistant
====================================================
â€¢ Stronglyâ€‘typed, fully documented LangChain tools.
â€¢ JIRA retriever converted to **StructuredTool** â‡’ uÅ¾ Å¾Ã¡dnÃ¡ chyba pÅ™i volÃ¡nÃ­ bez argumentÅ¯.
â€¢ Tavily & RAG unchanged, jen drobnÃ© kosmetickÃ© fixy.
"""
from __future__ import annotations

import os
from datetime import datetime
from pathlib import Path
from typing import List, Optional

import openai
from pydantic import BaseModel, Field
from langchain.tools import Tool, StructuredTool
from langchain_community.tools import DuckDuckGoSearchRun, WikipediaQueryRun
from langchain_community.utilities import WikipediaAPIWrapper
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain.schema import Document
from jira_retriever import fetch_jira_issues  # local helper for JIRA REST API
from tavily import TavilyClient

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Telemetry optâ€‘out â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
os.environ.setdefault("OPENAI_TELEMETRY", "0")
if hasattr(openai, "telemetry") and hasattr(openai.telemetry, "TelemetryClient"):
    openai.telemetry.TelemetryClient.capture = lambda *_, **__: None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Helper: Robust TXT Saver â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
OUTPUT_DIR = Path("output"); OUTPUT_DIR.mkdir(exist_ok=True)

def _save_to_txt(data: str, prefix: str = "research") -> str:
    """
    UloÅ¾Ã­ *data* do novÃ©ho TXT souboru v ./output a vrÃ¡tÃ­ textovou hlÃ¡Å¡ku.
    NÃ¡zev souboru = <prefix>_YYYY-MM-DD_HH-MM-SS.txt
    """
    timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    filename  = f"{prefix}_{timestamp}.txt"
    path      = OUTPUT_DIR / filename

    path.write_text(data, encoding="utf-8")

    return f"âœ… Data saved to {path.as_posix()}"

save_tool = Tool(
    name="save_text_to_file",
    func=_save_to_txt,
    description=(
        "UloÅ¾Ã­ libovolnÃ½ text (napÅ™. rozpracovanou Idea, SWOT, userâ€‘story) do souboru v ./output.\n"
        "Params â†’ data (string, povinnÃ½); filename (volitelnÃ½). Pokud filename chybÃ­, vytvoÅ™Ã­ se research_YYYYâ€‘MMâ€‘DD.txt. "
        "VracÃ­ potvrzovacÃ­ zprÃ¡vu s cestou."
    ),
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ General Web Search â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_duck = DuckDuckGoSearchRun()
search_tool = Tool(
    name="searchWeb",
    func=_duck.run,
    description=(
        "RychlÃ© obecnÃ© vyhledÃ¡vÃ¡nÃ­ (DuckDuckGo). PouÅ¾ij pro definice, novinky, blogâ€‘posty.\n"
        "NevhodnÃ© pro detailnÃ­ konkurenÄnÃ­ analÃ½zu â€“ tam je lepÅ¡Ã­ tavily_search."
    ),
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Wikipedia Snippet â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=400)
wiki_tool = Tool(
    name="wikipedia_query",
    func=WikipediaQueryRun(api_wrapper=api_wrapper).run,
    description="ZÃ­skÃ¡ krÃ¡tkÃ© shrnutÃ­ z Wikipedie â€“ vhodnÃ© pro historickÃ© pozadÃ­, standardy, pojmy.",
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ RAG Retriever over Chroma â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CHROMA_DIR = "rag_chroma_db"
_embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
_retriever = Chroma(persist_directory=CHROMA_DIR, embedding_function=_embeddings).as_retriever(search_kwargs={"k": 4})

def _rag_lookup(query: str) -> str:
    docs: List[Document] = _retriever.invoke(query)
    if not docs:
        return "Å½Ã¡dnÃ© internÃ­ dokumenty se k dotazu nenaÅ¡ly."
    return "\n\n".join(d.page_content for d in docs)

rag_tool = Tool(
    name="rag_retriever",
    func=_rag_lookup,
    description=(
        "ProhledÃ¡ internÃ­ znalostnÃ­ bÃ¡zi Productoo (uÅ¾ivatelskÃ¡ dokumentace P4, Roadmapa, archiv konverzacÃ­).\n"
        "VracÃ­ aÅ¾ 4 nejrelevantnÄ›jÅ¡Ã­ Ãºryvky. VhodnÃ© pro: funkce APS/CMMS, scÃ©nÃ¡Å™e vÃ½roby, Roadmapu."
    ),
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ JIRA Ideas Retriever (Structured) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class JiraIdeasInput(BaseModel):
    """Optional keyword filter for JIRA Ideas."""
    keyword: Optional[str] = Field(default=None, description="KlÃ­ÄovÃ© slovo pro filtrovÃ¡nÃ­ Ideas podle summary/description. Pokud None, vrÃ¡tÃ­ vÅ¡e.")


def _jira_ideas_struct(keyword: Optional[str] = None) -> str:
    try:
        issues = fetch_jira_issues()
    except Exception as exc:
        return f"âŒ Chyba pÅ™i naÄÃ­tÃ¡nÃ­ JIRA: {exc}"

    if not issues:
        return "Nenalezeny Å¾Ã¡dnÃ© JIRA Ideas."

    if keyword:
        issues = [iss for iss in issues if keyword.lower() in (iss["summary"] + iss["description"]).lower()]
        if not issues:
            return f"ğŸ” Å½Ã¡dnÃ© Ideas neobsahujÃ­ klÃ­ÄovÃ© slovo '{keyword}'."

    lines = [
        f"{iss['key']} | {iss['status']} | {iss['summary']}\n{iss['description'] or '- Å¾Ã¡dnÃ½ popis -'}"
        for iss in issues
    ]
    return "\n\n".join(lines)

jira_ideas = StructuredTool.from_function(
    func=_jira_ideas_struct,
    name="jira_ideas_retriever",
    description=(
        "NaÄte backlog *Ideas* z JIRA (projekt=P4). VhodnÃ© pro: \n"
        " â€¢ ovÄ›Å™enÃ­ duplicitnÃ­ch nÃ¡padÅ¯\n"
        " â€¢ rozpracovÃ¡nÃ­ existujÃ­cÃ­ch Ideas do detailu\n"
        " â€¢ nÃ¡vrh akceptaÄnÃ­ch kritÃ©riÃ­\n"
        "VolitelnÃ½ parametr `keyword` umoÅ¾Åˆuje filtrovat Ideas podle textu. Pokud keyword chybÃ­, vrÃ¡tÃ­ celÃ© backlog."
    ),
    args_schema=JiraIdeasInput,
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Tavily Semantic Search â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_TAVILY_KEY = os.getenv("TAVILY_API_KEY"); _client: TavilyClient | None = None
if _TAVILY_KEY:
    _client = TavilyClient(api_key=_TAVILY_KEY)

def _tavily_search(query: str) -> str:
    if _client is None:
        return "âŒ Tavily nenÃ­ nakonfigurovÃ¡no (chybÃ­ TAVILY_API_KEY)."

    try:
        raw = _client.search(query=query, max_results=6)
    except Exception as exc:
        return f"âŒ Tavily search selhalo: {exc}"

    results = raw.get("results", [])
    if not results:
        return "â›”ï¸ Tavily nic nenaÅ¡lo."

    snippets = [f"- {r['url']}\n  {r['content'][:400].strip()}â€¦" for r in results]
    return "\n\n".join(snippets)

tavily_tool = Tool(
    name="tavily_search",
    func=_tavily_search,
    description=(
        "PokroÄilÃ© sÃ©mantickÃ© vyhledÃ¡vÃ¡nÃ­ (LLM). VhodnÃ© pro: \n"
        " â€¢ konkurenÄnÃ­ analÃ½zu APS/CMMS\n        â€¢ whiteâ€‘papers, tiskovÃ© zprÃ¡vy, trendy trhu\n"
        "VracÃ­ aÅ¾ 6 vÃ½sledkÅ¯ (URL + snippet). VyÅ¾aduje promÄ›nnou prostÅ™edÃ­ TAVILY_API_KEY."
    ),
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Exports â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
__all__ = [
    "search_tool",
    "wiki_tool",
    "rag_tool",
    "jira_ideas",
    "tavily_tool",
    "save_tool",
]
